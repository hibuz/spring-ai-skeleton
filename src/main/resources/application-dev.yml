spring:
  ai:
    ollama:
      base-url: http://ollama:11434/
      init:
        pull-model-strategy: when_missing
        chat.additional-models:
          - llama3.2

management:
  endpoints:
    web:
      exposure:
        include: health,info,beans,conditions
        exclude: threaddump, heapdump